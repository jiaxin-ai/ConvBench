## Evaluation

To generate the multi-turn responses for each sample in ConvBench via each Large Vision-Language Model.

```shell
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "blip2-flan-t5-xxl"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "blip2-flan-t5-xxl"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "InternVL-Chat-V1-2"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "llama_adapter_v2_multimodal7b"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "llava_v1.5_7b"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "llava_v1.5_13b"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "MMAlaya"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "monkey-chat"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "mPLUG-Owl2"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "qwen_chat"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "sharegpt4v_7b"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "sharegpt4v_13b"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "XComposer"
python /mnt/lustre/liushuo/VLMEvalKit/run_multi_turn.py --data "mte" --model "XComposer2"
```

